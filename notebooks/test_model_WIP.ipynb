{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annoy in /Users/mrpapa/miniforge3/envs/nlp/lib/python3.8/site-packages (1.17.2)\n",
      "Requirement already satisfied: efficient-apriori in /Users/mrpapa/miniforge3/envs/nlp/lib/python3.8/site-packages (2.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install annoy\n",
    "!pip install efficient-apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: art in /Users/mrpapa/miniforge3/envs/nlp/lib/python3.8/site-packages (5.9)\n",
      "Requirement already satisfied: plotly in /Users/mrpapa/miniforge3/envs/nlp/lib/python3.8/site-packages (5.14.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/mrpapa/miniforge3/envs/nlp/lib/python3.8/site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: packaging in /Users/mrpapa/miniforge3/envs/nlp/lib/python3.8/site-packages (from plotly) (23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install art\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 60] Operation\n",
      "[nltk_data]     timed out>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg  width=\"550\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#eaf7e6;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#d8f0d2;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#c1e6ba;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#a4da9e;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#84cc83;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#62bb6d;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"330\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#3fa85b;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"385\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#289049;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"440\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#107a37;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"495\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#006227;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.9176931949250289, 0.9684275278738947, 0.901361014994233),\n",
       " (0.8459054209919262, 0.9399307958477509, 0.8228219915417148),\n",
       " (0.7558477508650518, 0.9033910034602076, 0.7290426758938869),\n",
       " (0.6436447520184544, 0.8561476355247981, 0.6197923875432525),\n",
       " (0.5185697808535179, 0.7983391003460207, 0.5150941945405614),\n",
       " (0.3827450980392157, 0.7332564398308343, 0.42737408688965783),\n",
       " (0.2452133794694348, 0.6602537485582468, 0.35695501730103807),\n",
       " (0.1566320645905421, 0.5657670126874279, 0.28608996539792386),\n",
       " (0.06082276047673972, 0.47958477508650516, 0.21599384851980008),\n",
       " (0.0, 0.38268358323721646, 0.15398692810457515)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.common import flatten\n",
    "from annoy import AnnoyIndex\n",
    "from gensim.models import Word2Vec\n",
    "from efficient_apriori import apriori\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import zipfile as zp\n",
    "from art import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF\n",
    "import plotly.express as px\n",
    "\n",
    "# from PyDictionary import PyDictionary P\n",
    "import random\n",
    "import time\n",
    "\n",
    "#import scikitplot as skplt\n",
    "\n",
    "#to enable the inline plotting\n",
    "%matplotlib inline \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.color_palette(\"Greens\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Seaborn color palette to use\n",
    "colors = sns.color_palette(\"Greens\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the fig size of all figures\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "# the directory to unzip the data in\n",
    "data_directory_path = '/Users/mrpapa/upwork/nlp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the days and hours from numbers to their interpretable form\n",
    "import datetime\n",
    "days_of_week = {0: 'Saturday', \n",
    "                1: 'Sunday', \n",
    "                2: 'Monday',\n",
    "                3: 'Tuesday',\n",
    "                4: 'Wednesday',\n",
    "                5: 'Thursday',\n",
    "                6: 'Friday'}\n",
    "hour_nums = list(range(24))\n",
    "hours_of_day = {hour_num:datetime.time(hour_num).strftime(\"%I:00 %p\") for hour_num in hour_nums}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate text on graph\n",
    "def annotate_text(p, append_to_text='%'):\n",
    "    for p in ax.patches:\n",
    "        txt = str(p.get_height().round(2)) + append_to_text\n",
    "        txt_x = p.get_x() + p.get_width()/2.\n",
    "        txt_y = 0.92*p.get_height()\n",
    "        ax.text(txt_x,txt_y,txt, fontsize=12, color='Black', ha='center', va='bottom')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Instacart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv files into corresponding dataframes\n",
    "aisles = pd.read_csv(\"data/aisles.csv\")\n",
    "order_products_prior = pd.read_csv(\"data/order_products__prior.csv\")\n",
    "order_products_train = pd.read_csv(\"data/order_products__train.csv\")\n",
    "products = pd.read_csv(\"data/products.csv\")\n",
    "orders = pd.read_csv(\"data/orders.csv\")\n",
    "departments = pd.read_csv(\"data/departments.csv\")\n",
    "\n",
    "# Replacing numbers with their corresponding day of week\n",
    "# Define the categories of days of week sorted normally from Saturday to Friday\n",
    "orders['order_dow'] = orders['order_dow'].replace(to_replace=days_of_week)\n",
    "\n",
    "orders['order_daytime'] = orders['order_dow'] + orders['order_hour_of_day'].astype('str')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting the number of orders to process\n",
    "orders_limit = 100000\n",
    "# Color constants for the console\n",
    "COLOR_CONSTANT = {'input': '\\033[94m', 'warning': '\\033[93m', 'error': '\\033[91m', 'note': '\\033[96m', 'end': '\\033[0m'}\n",
    "# Number of orders/baskets to pull similar to the requested\n",
    "orders_returns = 15\n",
    "# Number of dimensions of the vector annoy is going to store. \n",
    "vector_size = 64\n",
    "# Number of trees for queries. When making a query the more trees the easier it is to go down the right path. \n",
    "trees = 10\n",
    "# Number of product recommendation as maximum\n",
    "#NUMBER_OUTPUT_PRODUCTS = 10\n",
    "# Sample size for the TSNE model and plot\n",
    "tsne_size = 1000\n",
    "# Threshold for a minimum support\n",
    "threshold = 1e-3\n",
    "# Threshold for the maximun number of products to bring\n",
    "threshold_top = 10\n",
    "# Threshold for distance, based on the quantile calculation of the basket distances\n",
    "threshold_distance= 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['products_mod'] = products['product_name'].str.lower()\n",
    "# Clean special characters.\n",
    "products['products_mod'] = products['products_mod'].str.replace('\\W', ' ', regex=True)\n",
    "# Split products into terms: Tokenize.\n",
    "products['products_mod'] = products['products_mod'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the department and aisle names into the dataframe. \n",
    "products = pd.merge(products, departments, on=\"department_id\", how='outer')\n",
    "products = pd.merge(products, aisles, on=\"aisle_id\", how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove synonyms here in the list\n",
    "products['products_mod'] = products[['products_mod', 'aisle', 'department']].values.tolist()\n",
    "products['products_mod'] = products['products_mod'].apply(lambda x:list(flatten(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steam and lemmatisation of the product name\n",
    "# https://stackoverflow.com/a/25082458/3780957\n",
    "# https://en.wikipedia.org/wiki/Lemmatisation\n",
    "\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "sno = nltk.stem.SnowballStemmer('english')\n",
    "products['products_lemma'] = products['products_mod'].apply(lambda row:[lemma.lemmatize(item) for item in row])\n",
    "products['products_lemma'] = products['products_lemma'].apply(lambda row:[sno.stem(item) for item in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.to_csv(\"lemma_product.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49688it [00:01, 31659.58it/s]\n"
     ]
    }
   ],
   "source": [
    "### Training the `Word2Vec` model\n",
    "# The `Word2Vec` model is a shallow neural network that is trained to reconstruct linguistic contexts of words. <br>\n",
    "# The model takes as input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space. <br>\n",
    "# Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space. <br>\n",
    "# The model is trained by taking each sentence in the corpus, sliding a window of fixed size over it and trying to predict the word in the middle of the window, given the words on the sides of the window as input. <br>\n",
    "\n",
    "# Defining the maximun window\n",
    "window_max = max(products['products_lemma'].apply(lambda x:len(x)))\n",
    "\n",
    "# size=20: In order to make `Word2Vec` a little bit quicker and for memory efficiency we're going to use 20 dimensions.\n",
    "# window=49: In order to make sure all words are used in training the model, we're going to set a large.\n",
    "w2vec_model = Word2Vec(list(products['products_lemma']), vector_size=vector_size, window=window_max, min_count=1, workers=-1)\n",
    "\n",
    "### Vector calculation for products\n",
    "# Loop through each product and obtain the average of each string that makes a product. <br>\n",
    "# This will be the vector representation of the product. <br>\n",
    "# The vector representation of the product will be used to calculate the similarity between products. <br>\n",
    "# The similarity between products will be used to recommend products to the user. <br>\n",
    "\n",
    "# Loop through each word in the product name to generate the vector.\n",
    "prods_w2v = dict()\n",
    "for row, product in tqdm(products.iterrows()):\n",
    "    word_vector = list()\n",
    "    for word in product['products_lemma']:\n",
    "        word_vector.append(w2vec_model.wv[word])\n",
    "\n",
    "    prods_w2v[product['product_id']] = np.average(word_vector, axis=0)\n",
    "\n",
    "# Save vector values in list form to the dataframe.\n",
    "products['vectors'] = prods_w2v.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## TSNE model plot function\n",
    "# The `TSNE` model is a non-linear dimensionality reduction technique that is particularly well-suited for embedding high-dimensional data into a space of two or three dimensions, which can then be visualized in a scatter plot. <br>\n",
    "# Specifically, it models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points with high probability. <br>\n",
    "# The `TSNE` model is trained by taking as input a matrix of pairwise similarities between objects and converting them into probabilities using a Gaussian kernel. <br>\n",
    "# It then tries to minimize the Kullback–Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. <br>\n",
    "\n",
    "def tsne_plot(df, title, color=None, product_flag=False, auto_open=True, sample_size=tsne_size):\n",
    "    # Data sample, to speedup the execution\n",
    "    df_tsne_data = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    # Train the TSNE MODEL\n",
    "    tsne_model = TSNE(perplexity=30, n_components=2, init='pca', n_iter=3500, random_state=42)\n",
    "    new_values = tsne_model.fit_transform(np.array(list(df_tsne_data['vectors'])))\n",
    "\n",
    "    # Prepare data\n",
    "    x = list()\n",
    "    y = list()\n",
    "    for i in range(new_values.shape[0]):\n",
    "        x.append(new_values[i][0])\n",
    "        y.append(new_values[i][1])\n",
    "\n",
    "    if color is not None:\n",
    "        marker_ = dict(color=list(df_tsne_data[color]), colorscale='rdpu', showscale=False)\n",
    "        if product_flag:\n",
    "            text_ = df_tsne_data[['product_name', 'aisle', 'department']].agg('<br>'.join, axis=1)\n",
    "        else:\n",
    "            text_ = color + \": \" +  df_tsne_data[color].astype(str)\n",
    "    else:\n",
    "        marker_ = text_ = None\n",
    "    \n",
    "    trace = go.Scatter(\n",
    "        x = x,\n",
    "        y = y,\n",
    "        mode = 'markers',\n",
    "        text = text_,\n",
    "        hoverinfo = 'text',\n",
    "        marker = marker_\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title = title,\n",
    "        hovermode = 'closest',\n",
    "        xaxis = dict(title='Dimension one', autorange=True),\n",
    "        yaxis = dict(title='Dimension two', autorange=True))\n",
    "\n",
    "    # Create plot\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## TSNE model plot function, with selection ----\n",
    "\n",
    "def tsne_plot2(df, title, selection, hover=None, auto_open=True, sample_size=tsne_size):\n",
    "\n",
    "    # Data sample, to speedup the execution\n",
    "    df_tsne_data = df.sample(n=sample_size, random_state=42)\n",
    "    df_tsne_data['size'] = 1\n",
    "    df_tsne_data['color'] = 'Others'\n",
    "\n",
    "    selection = selection.copy()  # To avoid a warning\n",
    "    selection['size'] = 5\n",
    "    selection['color'] = 'Selection'\n",
    "\n",
    "    df_tsne_data = df_tsne_data.append(selection)\n",
    "\n",
    "    # Train the TSNE MODEL\n",
    "    tsne_model = TSNE(perplexity=30, n_components=2, init='pca', n_iter=3500, random_state=42)\n",
    "    tsne_values = tsne_model.fit_transform(np.array(list(df_tsne_data['vectors'])))\n",
    "\n",
    "    df_tsne_data['tsne-2d-one'] = tsne_values[:, 0]\n",
    "    df_tsne_data['tsne-2d-two'] = tsne_values[:, 1]\n",
    "\n",
    "    if hover is not None:\n",
    "        df_tsne_data['hover'] = df_tsne_data[hover]\n",
    "    else:\n",
    "        df_tsne_data['hover'] = df_tsne_data[['product_name', 'aisle', 'department']].agg('<br>'.join, axis=1)\n",
    "\n",
    "    df_tsne_data.sort_values(by='color', ascending=False, inplace=True)\n",
    "\n",
    "    fig = px.scatter(df_tsne_data, x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "                    color='color', \n",
    "                    size=\"size\", size_max=8,\n",
    "                    title=title,\n",
    "                    hover_data=['hover'],\n",
    "                    labels={\n",
    "                        \"tsne-2d-one\": \"Dimension one\",\n",
    "                        \"tsne-2d-two\": \"Dimension two\",\n",
    "                        \"color\": \"Color reference\"\n",
    "                    })\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using `annoy` model to calculate the similarity between products\n",
    "# The `annoy` model is a library to search for points in space that are close to a given query point. <br>\n",
    "# It also creates large read-only file-based data structures that are mmpped into memory so that many processes may share the same data. <br>\n",
    "# For our case, we will use the `annoy` model to calculate the similarity between products. <br>\n",
    "# The `annoy` model is trained by taking as input a matrix of pairwise similarities between objects and converting them into probabilities using a Gaussian kernel. <br>\n",
    "# It then tries to minimize the Kullback–Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. <br>\n",
    "\n",
    "def annoy_build(df, id, metric='euclidean'):\n",
    "    m = AnnoyIndex(vector_size, metric=metric) \n",
    "    m.set_seed(42)\n",
    "    for _, row in df.iterrows():\n",
    "        m.add_item(row[id], row['vectors'])\n",
    "    m.build(trees)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train `annoy` for `product` dataset\n",
    "# We need to specify ahead of time to annoy that there are 20 vector dimensions. Defined as a constant at `vector_size`.\n",
    "# We also specify we want the model to find distances using `euclidean` distance.\n",
    "\n",
    "# Specify the metric to be used for computing distances. \n",
    "p = annoy_build(products, 'product_id')\n",
    "p.save(\"product_build.annoy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "93947it [00:03, 31241.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train `annoy` for `orders` dataset\n",
    "# In order to obtain the vector for each list we need to import the orders csv. <br>\n",
    "# The order_products_prior has the order_id and the product_id (this is why we keeping product IDs as a key is useful).\n",
    "# limit the number of orders we are operating on. \n",
    "\n",
    "orders_filter = order_products_prior[order_products_prior.order_id < orders_limit]\n",
    "order_baskets = orders_filter.groupby('order_id')['product_id'].apply(list)\n",
    "\n",
    "order_w2v = dict()\n",
    "for index, row in tqdm(order_baskets.items()):\n",
    "    word_vector = list()\n",
    "    for item_id in row:\n",
    "        word_vector.append(p.get_item_vector(item_id))\n",
    "    order_w2v[index] = np.average(word_vector, axis=0)\n",
    "\n",
    "df_order_baskets = pd.DataFrame({'order_id': order_baskets.index, 'product_id': order_baskets.values})\n",
    "df_order_baskets['vectors'] = order_w2v.values()\n",
    "\n",
    "# Specify the metric to be used for computing distances. \n",
    "b = annoy_build(df_order_baskets, 'order_id')\n",
    "b.save(\"basket_build.annoy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['Coconut Creme Eggs', 'Easter Crème Eggs 4 Count, 4.8 oz pkg', 'Milk Chocolate Peanut Butter Eggs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "productid_map = dict(zip(products.product_name, products.product_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49688"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.product_id.nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49688"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.product_name.nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4491, 11612, 20254]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train `annoy` for `user` dataset\n",
    "# Creating an `annoy` object to index the `user` information\n",
    "\n",
    "user_basket = pd.merge(df_order_baskets, orders, on=\"order_id\", how='inner')\n",
    "user_basket = user_basket.groupby('user_id').apply(lambda x: [list(x['vectors']), list(x['product_id'])]).apply(pd.Series)\n",
    "user_basket.columns =['vectors','product_id']\n",
    "user_basket['vectors'] = user_basket['vectors'].apply(lambda x: tuple(np.average(x, axis=0)))\n",
    "user_basket['product_id'] = user_basket['product_id'].apply(lambda x: [item for sublist in x for item in sublist])\n",
    "user_basket['product_id'] = user_basket['product_id'].apply(lambda x: list(set(x)))\n",
    "df_user_basket = user_basket.reset_index()\n",
    "\n",
    "# Specify the metric to be used for computing distances. \n",
    "u = annoy_build(df_user_basket, 'user_id')\n",
    "u.save(\"user_build.annoy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train 'annoy' for 'day-time' dataset\n",
    "# Create day-time based order dataset\n",
    "# orders['order_dow'] = orders['order_dow'].astype('str') \n",
    "# orders['order_hour_of_day'] = pd.to_datetime(orders['order_hour_of_day'].astype('str'))\n",
    "# orders['order_hour_of_day'] = orders['order_hour_of_day'].apply(lambda x: x.strftime(\"%H\"))\n",
    "\n",
    "# orders['order_daytime'] = orders['order_dow'] + orders['order_hour_of_day']\n",
    "\n",
    "daytime_basket = pd.merge(df_order_baskets, orders, on=\"order_id\", how='inner')\n",
    "daytime_basket = daytime_basket.groupby('order_daytime').apply(lambda x: [list(x['vectors']), list(x['product_id'])]).apply(pd.Series)\n",
    "daytime_basket.columns =['vectors','product_id']\n",
    "daytime_basket['vectors'] = daytime_basket['vectors'].apply(lambda x: tuple(np.average(x, axis=0)))\n",
    "daytime_basket['product_id'] = daytime_basket['product_id'].apply(lambda x: [item for sublist in x for item in sublist])\n",
    "daytime_basket['product_id'] = daytime_basket['product_id'].apply(lambda x: list(set(x)))\n",
    "df_daytime_basket = daytime_basket.reset_index()\n",
    "\n",
    "# Specify the metric to be used for computing distances. \n",
    "df_daytime_basket = df_daytime_basket.reset_index().rename(columns={'index':'daytime_id'})\n",
    "d = annoy_build(df_daytime_basket, 'daytime_id')\n",
    "d.save(\"daytime_build.annoy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_baskets.to_pickle('order_basket.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_basket.to_csv(\"df_user_basket.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daytime_basket.to_csv(\"df_daytime_basket.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>products_mod</th>\n",
       "      <th>department</th>\n",
       "      <th>aisle</th>\n",
       "      <th>products_lemma</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>[chocolate, sandwich, cookies, cookies cakes, ...</td>\n",
       "      <td>snacks</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>[chocol, sandwich, cooki, cookies cak, snack]</td>\n",
       "      <td>[-3.445819e-05, -0.0009065453, -0.0018344745, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172</td>\n",
       "      <td>Gluten Free All Natural Chocolate Chip Cookies</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>[gluten, free, all, natural, chocolate, chip, ...</td>\n",
       "      <td>snacks</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>[gluten, free, all, natur, chocol, chip, cooki...</td>\n",
       "      <td>[0.0016820944, -0.0024560867, -0.0007397007, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>559</td>\n",
       "      <td>Cookie Chips Crunchy Dark Chocolate Chocolate ...</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>[cookie, chips, crunchy, dark, chocolate, choc...</td>\n",
       "      <td>snacks</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>[cooki, chip, crunchi, dark, chocol, chocol, c...</td>\n",
       "      <td>[0.00056251494, -0.0016667483, -0.0023854182, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>796</td>\n",
       "      <td>Chocolate Reese's Peanut Butter Cup Creme Oreo</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>[chocolate, reese, s, peanut, butter, cup, cre...</td>\n",
       "      <td>snacks</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>[chocol, rees, s, peanut, butter, cup, creme, ...</td>\n",
       "      <td>[-0.003945703, 0.00061626884, 0.0020643375, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1129</td>\n",
       "      <td>Organic Family Recipe Chocolate Chip Cookies</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>[organic, family, recipe, chocolate, chip, coo...</td>\n",
       "      <td>snacks</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>[organ, famili, recip, chocol, chip, cooki, co...</td>\n",
       "      <td>[0.0010658684, -0.0034217073, -0.002860622, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49307</th>\n",
       "      <td>19399</td>\n",
       "      <td>Organic Semi Sweet Chocolate Chips</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[organic, semi, sweet, chocolate, chips, other...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>[organ, semi, sweet, chocol, chip, other, other]</td>\n",
       "      <td>[0.0025311585, 0.001968342, 0.0010151336, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49330</th>\n",
       "      <td>20897</td>\n",
       "      <td>Milk Chocolate Coconut Bar</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[milk, chocolate, coconut, bar, other, other]</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>[milk, chocol, coconut, bar, other, other]</td>\n",
       "      <td>[-0.0019966848, 0.0017560007, 0.0011367133, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49410</th>\n",
       "      <td>28072</td>\n",
       "      <td>Dark Chocolate Malt Balls</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[dark, chocolate, malt, balls, other, other]</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>[dark, chocol, malt, ball, other, other]</td>\n",
       "      <td>[-0.0048537985, 0.0040092133, 0.0021434398, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49442</th>\n",
       "      <td>31197</td>\n",
       "      <td>Chocolate Covered Raisins</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[chocolate, covered, raisins, other, other]</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>[chocol, cover, raisin, other, other]</td>\n",
       "      <td>[-0.0069007664, 0.004802491, 0.0015015441, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49624</th>\n",
       "      <td>47856</td>\n",
       "      <td>Milk Chocolate Malt Balls</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[milk, chocolate, malt, balls, other, other]</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>[milk, chocol, malt, ball, other, other]</td>\n",
       "      <td>[-0.0026774008, 0.007381303, -0.0012301166, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2419 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id                                       product_name  \\\n",
       "0               1                         Chocolate Sandwich Cookies   \n",
       "3             172     Gluten Free All Natural Chocolate Chip Cookies   \n",
       "7             559  Cookie Chips Crunchy Dark Chocolate Chocolate ...   \n",
       "16            796     Chocolate Reese's Peanut Butter Cup Creme Oreo   \n",
       "18           1129       Organic Family Recipe Chocolate Chip Cookies   \n",
       "...           ...                                                ...   \n",
       "49307       19399                 Organic Semi Sweet Chocolate Chips   \n",
       "49330       20897                         Milk Chocolate Coconut Bar   \n",
       "49410       28072                          Dark Chocolate Malt Balls   \n",
       "49442       31197                          Chocolate Covered Raisins   \n",
       "49624       47856                          Milk Chocolate Malt Balls   \n",
       "\n",
       "       aisle_id  department_id  \\\n",
       "0            61             19   \n",
       "3            61             19   \n",
       "7            61             19   \n",
       "16           61             19   \n",
       "18           61             19   \n",
       "...         ...            ...   \n",
       "49307         6              2   \n",
       "49330         6              2   \n",
       "49410         6              2   \n",
       "49442         6              2   \n",
       "49624         6              2   \n",
       "\n",
       "                                            products_mod department  \\\n",
       "0      [chocolate, sandwich, cookies, cookies cakes, ...     snacks   \n",
       "3      [gluten, free, all, natural, chocolate, chip, ...     snacks   \n",
       "7      [cookie, chips, crunchy, dark, chocolate, choc...     snacks   \n",
       "16     [chocolate, reese, s, peanut, butter, cup, cre...     snacks   \n",
       "18     [organic, family, recipe, chocolate, chip, coo...     snacks   \n",
       "...                                                  ...        ...   \n",
       "49307  [organic, semi, sweet, chocolate, chips, other...      other   \n",
       "49330      [milk, chocolate, coconut, bar, other, other]      other   \n",
       "49410       [dark, chocolate, malt, balls, other, other]      other   \n",
       "49442        [chocolate, covered, raisins, other, other]      other   \n",
       "49624       [milk, chocolate, malt, balls, other, other]      other   \n",
       "\n",
       "               aisle                                     products_lemma  \\\n",
       "0      cookies cakes      [chocol, sandwich, cooki, cookies cak, snack]   \n",
       "3      cookies cakes  [gluten, free, all, natur, chocol, chip, cooki...   \n",
       "7      cookies cakes  [cooki, chip, crunchi, dark, chocol, chocol, c...   \n",
       "16     cookies cakes  [chocol, rees, s, peanut, butter, cup, creme, ...   \n",
       "18     cookies cakes  [organ, famili, recip, chocol, chip, cooki, co...   \n",
       "...              ...                                                ...   \n",
       "49307          other   [organ, semi, sweet, chocol, chip, other, other]   \n",
       "49330          other         [milk, chocol, coconut, bar, other, other]   \n",
       "49410          other           [dark, chocol, malt, ball, other, other]   \n",
       "49442          other              [chocol, cover, raisin, other, other]   \n",
       "49624          other           [milk, chocol, malt, ball, other, other]   \n",
       "\n",
       "                                                 vectors  \n",
       "0      [-3.445819e-05, -0.0009065453, -0.0018344745, ...  \n",
       "3      [0.0016820944, -0.0024560867, -0.0007397007, 0...  \n",
       "7      [0.00056251494, -0.0016667483, -0.0023854182, ...  \n",
       "16     [-0.003945703, 0.00061626884, 0.0020643375, 0....  \n",
       "18     [0.0010658684, -0.0034217073, -0.002860622, 0....  \n",
       "...                                                  ...  \n",
       "49307  [0.0025311585, 0.001968342, 0.0010151336, -0.0...  \n",
       "49330  [-0.0019966848, 0.0017560007, 0.0011367133, -0...  \n",
       "49410  [-0.0048537985, 0.0040092133, 0.0021434398, -0...  \n",
       "49442  [-0.0069007664, 0.004802491, 0.0015015441, -0....  \n",
       "49624  [-0.0026774008, 0.007381303, -0.0012301166, -0...  \n",
       "\n",
       "[2419 rows x 9 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the string you want to search for\n",
    "search_string = 'chocol'\n",
    "\n",
    "# Filter rows based on the presence of the search string in the list\n",
    "products[products['products_lemma'].apply(lambda x: search_string in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [chocol, sandwich, cooki, cookies cak, snack]\n",
       "1        [nutter, butter, cooki, bite, go, pak, cookies...\n",
       "2              [danish, butter, cooki, cookies cak, snack]\n",
       "3        [gluten, free, all, natur, chocol, chip, cooki...\n",
       "4        [mini, nilla, wafer, munch, pack, cookies cak,...\n",
       "                               ...                        \n",
       "49683    [organ, black, mission, fig, bulk dried fruits...\n",
       "49684    [crystal, ginger, chunk, bulk dried fruits veg...\n",
       "49685         [veget, chip, bulk dried fruits veget, bulk]\n",
       "49686    [natur, sweet, plantain, chip, bulk dried frui...\n",
       "49687    [fit, super, a, juic, cold, press, carrot, app...\n",
       "Name: products_lemma, Length: 49688, dtype: object"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['products_lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Similarity between products\n",
    "### Define the function to calculate the similarity between products\n",
    "\n",
    "# List the unique products maintaining the original order\n",
    "def unique_preserve_order(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "# Sort recommendations by `lift`, and filter if the products are too close\n",
    "def product_lift(basket, input = None, order_baskets=order_baskets, th_support=threshold, th_n=threshold_top, products=products):\n",
    "    # Force to include the manual `input`\n",
    "    recommendations = basket['product_id'].tolist()\n",
    "    if input is not None:\n",
    "        recommendations.extend(input)\n",
    "    recommendations = set(recommendations)\n",
    "\n",
    "    # Baskets with only the recommended products by the w2v\n",
    "    order_baskets_ = order_baskets.explode()\n",
    "    order_baskets_ = order_baskets_[order_baskets_.isin(recommendations)]\n",
    "    order_baskets_ = order_baskets_.groupby(level=0).apply(list)\n",
    "    order_baskets_ = order_baskets_.to_list()\n",
    "\n",
    "    # Calculate `apriori` rules using a efficient library to speed up the calculation\n",
    "    _, rules = apriori(order_baskets_, min_support=th_support, min_confidence=1e-2, max_length=5)\n",
    "    \n",
    "    # Multiple filters, but due to the lack of orders, are limiting the number of results, so a simple filter is active\n",
    "    if input is not None:\n",
    "        rules_rhs = filter(lambda rule: \\\n",
    "            not all(x in rule.rhs for x in input)\n",
    "            , rules)\n",
    "    else:\n",
    "        rules_rhs = rules\n",
    "\n",
    "    # Combine all the rules found in the data\n",
    "    # Sorted by highest lift\n",
    "    rule_combined = list()\n",
    "    for rule in sorted(rules_rhs, key=lambda rule: rule.lift, reverse=True):\n",
    "        # print(rule)\n",
    "        rule_combined.extend(rule.rhs)\n",
    "\n",
    "    # List the unique products maintaining the original order\n",
    "    product_recommendation = unique_preserve_order(rule_combined)\n",
    "\n",
    "    ## The following code, filters the recommendations after `lift`, based on the distance between the products\n",
    "    # List of products\n",
    "    prod = pd.DataFrame({'product_id': product_recommendation})\n",
    "    prod_cross_join = prod.merge(prod, how='cross')\n",
    "    # Calculate the distance between all the products\n",
    "    prod_cross_join['distance'] = prod_cross_join.apply(lambda row: p.get_distance(row['product_id_x'], row['product_id_y']), axis=1)\n",
    "    # Remove the same product (distance==0)\n",
    "    prod_cross_join = prod_cross_join[prod_cross_join['distance']!=0]\n",
    "    prod_cross_join.sort_values('distance', ascending=False)\n",
    "    # Looking for closest products\n",
    "    # Threshold for the filter, 10% of the distance (defined at `threshold_distance` constant)\n",
    "    th_distance = np.quantile(prod_cross_join, threshold_distance)\n",
    "    for id in product_recommendation:\n",
    "        to_be_removed = prod_cross_join.loc[(prod_cross_join['product_id_x']==id) & (prod_cross_join['distance']<th_distance), 'product_id_y']\n",
    "        prod_cross_join = prod_cross_join[~prod_cross_join['product_id_x'].isin(to_be_removed)]\n",
    "    # List of final recommendations after the filters and thresholds\n",
    "    prod_after_filtered = prod_cross_join['product_id_x'].unique()\n",
    "    # Retain the order from the `lift`\n",
    "    product_recommendation_filtered = pd.DataFrame({'product_recommendation': product_recommendation}).set_index('product_recommendation').loc[prod_after_filtered].reset_index()\n",
    "    # Recall the products in the previous order\n",
    "    product_recommendation_product = products.set_index(\"product_id\").loc[product_recommendation_filtered['product_recommendation']].reset_index()\n",
    "\n",
    "    return product_recommendation_product[['product_name', 'department', 'aisle']].head(th_n)\n",
    "\n",
    "# Finds the recommended basket, based on the `Word2Vec` vector as input\n",
    "def basket_recompose(w2v, b=b, order_baskets=order_baskets):\n",
    "    # Search for a similar basket in `b`\n",
    "    similar_baskets = b.get_nns_by_vector(w2v, orders_returns, search_k=-1, include_distances=False)\n",
    "    basket_recompose = pd.DataFrame({'order_id': similar_baskets, 'product_id': order_baskets[similar_baskets].values}).explode('product_id')\n",
    "\n",
    "    return basket_recompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "daytime_w2v = d.get_item_vector(0)\n",
    "basket_dt = basket_recompose(daytime_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate baskets based on different inputs\n",
    "# Based on different inputs, a different method of calculating a basket.\n",
    "\n",
    "def basket_multi_input(product_list=[], user_list=[], daytime=None):\n",
    "\n",
    "    basket_main = pd.DataFrame()\n",
    "    input_product_list = []\n",
    "    \n",
    "    # Product list\n",
    "    product_w2v = None\n",
    "    if product_list:\n",
    "        p_word_vector = list()\n",
    "        for item_id in product_list:\n",
    "            p_word_vector.append(p.get_item_vector(item_id))\n",
    "        product_w2v = np.average(p_word_vector, axis=0)\n",
    "\n",
    "        # Search for a similar basket in `b`\n",
    "        basket_prod = basket_recompose(product_w2v)\n",
    "        # Remove the manually selected products. Cleanup the output\n",
    "        basket_prod = basket_prod[~basket_prod['product_id'].isin(product_list)]\n",
    "        input_product_list = input_product_list + product_list\n",
    "        basket_main = pd.concat([basket_main, basket_prod], axis=0)\n",
    "    \n",
    "    # User list\n",
    "    selection_w2v = None\n",
    "    if user_list:\n",
    "        u_word_vector = list()\n",
    "        for item_id in user_list:\n",
    "            u_word_vector.append(tuple(u.get_item_vector(item_id)))\n",
    "        user_w2v = np.average(u_word_vector, axis=0)\n",
    "        basket = basket_recompose(user_w2v)\n",
    "        # Products from the list of users\n",
    "        input = df_user_basket.loc[df_user_basket['user_id'].isin(x), 'product_id']\n",
    "        input = [item for sublist in input for item in sublist]\n",
    "        input_product_list = input_product_list + input\n",
    "        \n",
    "        basket_main = pd.concat([basket_main, basket], axis=0)\n",
    "\n",
    "    if daytime is not None:\n",
    "        daytime_w2v = d.get_item_vector(daytime)\n",
    "        basket_dt = basket_recompose(daytime_w2v)\n",
    "\n",
    "        input = df_daytime_basket.loc[df_daytime_basket['daytime_id'] == daytime, 'product_id'].item()\n",
    "        input_product_list = input_product_list + input\n",
    "        basket_main = pd.concat([basket_main, basket_dt], axis=0)\n",
    "    \n",
    "    return product_lift(basket_main, input_product_list)\n",
    "    \n",
    "# From a list of products, recommends a basket\n",
    "def basket_input_product_list(x):\n",
    "    word_vector = list()\n",
    "    for item_id in x:\n",
    "        word_vector.append(p.get_item_vector(item_id))\n",
    "    product_w2v = np.average(word_vector, axis=0)\n",
    "\n",
    "    # Search for a similar basket in `b`\n",
    "    basket = basket_recompose(product_w2v)\n",
    "    # Remove the manually selected products. Cleanup the output\n",
    "    basket = basket[~basket['product_id'].isin(x)]\n",
    "    \n",
    "    basket_input = products[products['product_id'].isin(x)]\n",
    "    basket_input_names = basket_input['product_name'].values\n",
    "\n",
    "    return product_lift(basket, x), basket_input_names, basket_input\n",
    "\n",
    "# Form a particular user, recommends a basket. Also report the users that are similar to the input.\n",
    "def basket_input_user(x):\n",
    "    user_w2v = u.get_item_vector(x)\n",
    "    selection_w2v = pd.DataFrame({'user_id': x, 'vectors': [tuple(user_w2v),]})\n",
    "\n",
    "    # Search for similar users in `u`\n",
    "    similar_users = u.get_nns_by_item(x, orders_returns, search_k=-1, include_distances=False)[1:]\n",
    "\n",
    "    # Products from the user\n",
    "    input = df_user_basket.loc[df_user_basket['user_id'] == x, 'product_id'][0]\n",
    "    products_user_input = products[products['product_id'].isin(input)]\n",
    "    products_user_input_name = products_user_input['product_name'].tolist()\n",
    "\n",
    "    # Search for a similar basket in `b`\n",
    "    basket = basket_recompose(user_w2v)\n",
    "    return product_lift(basket, input), similar_users, selection_w2v, products_user_input_name\n",
    "\n",
    "# From a list of users, recommends a basket\n",
    "def basket_input_user_list(x):\n",
    "    word_vector = list()\n",
    "    for item_id in x:\n",
    "        word_vector.append(tuple(u.get_item_vector(item_id)))\n",
    "    user_w2v = np.average(word_vector, axis=0)\n",
    "    # Selected users\n",
    "    selection_w2v = pd.DataFrame({'user_id': list(x,), 'vectors': list(word_vector,)})\n",
    "\n",
    "    # Products from the list of users\n",
    "    input = df_user_basket.loc[df_user_basket['user_id'].isin(x), 'product_id']\n",
    "    input = [item for sublist in input for item in sublist]\n",
    "    products_user_input = products[products['product_id'].isin(input)]\n",
    "    products_user_input_name = products_user_input['product_name'].tolist()\n",
    "\n",
    "    # Search for a similar basket in `b`\n",
    "    basket = basket_recompose(user_w2v)\n",
    "    return product_lift(basket, input), x, selection_w2v, products_user_input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 s, sys: 170 ms, total: 1.17 s\n",
      "Wall time: 1.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = [33120, 28985, 9327]\n",
    "df = basket_multi_input([33120, 28985, 9327], [206205, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 576 ms, sys: 130 ms, total: 706 ms\n",
      "Wall time: 778 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = [33120]\n",
    "df = basket_multi_input([33120], [206205])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>department</th>\n",
       "      <th>aisle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organic Garlic</td>\n",
       "      <td>produce</td>\n",
       "      <td>fresh vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Limes</td>\n",
       "      <td>produce</td>\n",
       "      <td>fresh fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Organic Hass Avocado</td>\n",
       "      <td>produce</td>\n",
       "      <td>fresh fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Green Bell Pepper</td>\n",
       "      <td>produce</td>\n",
       "      <td>fresh vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Organic Low Sodium Chicken Broth</td>\n",
       "      <td>canned goods</td>\n",
       "      <td>soup broth bouillon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Feta Cheese Crumbles</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>packaged cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Organic Whole Milk</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Organic Extra Firm Tofu</td>\n",
       "      <td>deli</td>\n",
       "      <td>tofu meat alternatives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Total Greek Strained Yogurt</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Uncured Genoa Salami</td>\n",
       "      <td>deli</td>\n",
       "      <td>lunch meat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       product_name    department                   aisle\n",
       "0                    Organic Garlic       produce        fresh vegetables\n",
       "1                             Limes       produce            fresh fruits\n",
       "2              Organic Hass Avocado       produce            fresh fruits\n",
       "3                 Green Bell Pepper       produce        fresh vegetables\n",
       "4  Organic Low Sodium Chicken Broth  canned goods     soup broth bouillon\n",
       "5              Feta Cheese Crumbles    dairy eggs         packaged cheese\n",
       "6                Organic Whole Milk    dairy eggs                    milk\n",
       "7           Organic Extra Firm Tofu          deli  tofu meat alternatives\n",
       "8       Total Greek Strained Yogurt    dairy eggs                  yogurt\n",
       "9              Uncured Genoa Salami          deli              lunch meat"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_prod = basket_recompose(pw)\n",
    "basket_prod = basket_prod[~basket_prod['product_id'].isin(x)]\n",
    "\n",
    "basket_user = basket_recompose(uw)\n",
    "basket_user = basket_user[~basket_user['product_id'].isin(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "function missing required argument 'f' (pos 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mAnnoyIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: function missing required argument 'f' (pos 1)"
     ]
    }
   ],
   "source": [
    "s = AnnoyIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "descriptor 'load' for 'annoy.Annoy' objects doesn't apply to a 'str' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mAnnoyIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbasket_build.annoy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: descriptor 'load' for 'annoy.Annoy' objects doesn't apply to a 'str' object"
     ]
    }
   ],
   "source": [
    "s = AnnoyIndex.load(\"basket_build.annoy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30805</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30805</td>\n",
       "      <td>23085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30805</td>\n",
       "      <td>2469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30805</td>\n",
       "      <td>32137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30805</td>\n",
       "      <td>21026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35940</td>\n",
       "      <td>27521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35940</td>\n",
       "      <td>17794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35940</td>\n",
       "      <td>44683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35940</td>\n",
       "      <td>45200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35940</td>\n",
       "      <td>40706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id product_id\n",
       "0      30805        945\n",
       "0      30805      23085\n",
       "0      30805       2469\n",
       "0      30805      32137\n",
       "0      30805      21026\n",
       "..       ...        ...\n",
       "14     35940      27521\n",
       "14     35940      17794\n",
       "14     35940      44683\n",
       "14     35940      45200\n",
       "14     35940      40706\n",
       "\n",
       "[394 rows x 2 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([basket_user, basket_prod], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8353</td>\n",
       "      <td>48775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8353</td>\n",
       "      <td>23165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8353</td>\n",
       "      <td>13114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8353</td>\n",
       "      <td>36144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8353</td>\n",
       "      <td>45044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35940</td>\n",
       "      <td>27521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35940</td>\n",
       "      <td>17794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35940</td>\n",
       "      <td>44683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35940</td>\n",
       "      <td>45200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35940</td>\n",
       "      <td>40706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id product_id\n",
       "0       8353      48775\n",
       "0       8353      23165\n",
       "0       8353      13114\n",
       "0       8353      36144\n",
       "0       8353      45044\n",
       "..       ...        ...\n",
       "14     35940      27521\n",
       "14     35940      17794\n",
       "14     35940      44683\n",
       "14     35940      45200\n",
       "14     35940      40706\n",
       "\n",
       "[174 rows x 2 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 753 ms, sys: 106 ms, total: 860 ms\n",
      "Wall time: 888 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>department</th>\n",
       "      <th>aisle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organic Rosemary</td>\n",
       "      <td>produce</td>\n",
       "      <td>fresh herbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Limes</td>\n",
       "      <td>produce</td>\n",
       "      <td>fresh fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Organic Hass Avocado</td>\n",
       "      <td>produce</td>\n",
       "      <td>fresh fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Organic Zucchini</td>\n",
       "      <td>produce</td>\n",
       "      <td>fresh vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Green Bell Pepper</td>\n",
       "      <td>produce</td>\n",
       "      <td>fresh vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Organic Low Sodium Chicken Broth</td>\n",
       "      <td>canned goods</td>\n",
       "      <td>soup broth bouillon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Feta Cheese Crumbles</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>packaged cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Organic Extra Firm Tofu</td>\n",
       "      <td>deli</td>\n",
       "      <td>tofu meat alternatives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Organic Whole Milk</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Total Greek Strained Yogurt</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>yogurt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       product_name    department                   aisle\n",
       "0                  Organic Rosemary       produce             fresh herbs\n",
       "1                             Limes       produce            fresh fruits\n",
       "2              Organic Hass Avocado       produce            fresh fruits\n",
       "3                  Organic Zucchini       produce        fresh vegetables\n",
       "4                 Green Bell Pepper       produce        fresh vegetables\n",
       "5  Organic Low Sodium Chicken Broth  canned goods     soup broth bouillon\n",
       "6              Feta Cheese Crumbles    dairy eggs         packaged cheese\n",
       "7           Organic Extra Firm Tofu          deli  tofu meat alternatives\n",
       "8                Organic Whole Milk    dairy eggs                    milk\n",
       "9       Total Greek Strained Yogurt    dairy eggs                  yogurt"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "product_lift(basket, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run user interface ----\n",
    "clear_console()\n",
    "\n",
    "INPUT_TYPES = {1: 'Input product [Using name]', 2: 'Input product [Using ID]', 3: 'Input user', 4: 'Input users list', 5: 'Input order', 6: 'TSNE plots', 7: 'Auto EDA', 8: 'Orders and frequency EDA', 9: 'Exit'}\n",
    "select_continue = 1  # Start the loop\n",
    "\n",
    "# Infinite loop, will stop  by pressing Ctrl+C or selecting 'Exit' when prompt\n",
    "while select_continue < max(INPUT_TYPES.keys()):\n",
    "    # Prompt the user to continue or stop the infinite rounds\n",
    "    select_continue = read_positive(message_try='Choose the type of input %s: ' % (\n",
    "                                        ' '.join('\\n{}: {}'.format(k, v) for k, v in INPUT_TYPES.items())),\n",
    "                                    message_error='Only accepts the values %s, try again.' % (tuple(INPUT_TYPES.keys()),)\n",
    "                                    )\n",
    "\n",
    "    if select_continue < max(INPUT_TYPES.keys()) :\n",
    "        clear_console()\n",
    "        tprint(INPUT_TYPES[select_continue], \"Standard\")\n",
    "\n",
    "    # Selection based on the key from `INPUT_TYPES`\n",
    "    if select_continue == 1:\n",
    "        # Multiple entries until the user press `Enter` to finish\n",
    "        # https://www.geeksforgeeks.org/python-get-a-list-as-input-from-user/\n",
    "        try:\n",
    "            select_list = list()\n",
    "            while True:\n",
    "                select_ = read_product_name()\n",
    "                if select_:\n",
    "                    select_list.append(select_)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "        except:\n",
    "            out_ = basket_input_product_list(select_list)\n",
    "            print_color('Selected:')\n",
    "            print(out_[1])\n",
    "            print('\\n')\n",
    "            print_color('Recommendation:')\n",
    "            print(out_[0])\n",
    "            print('\\n')\n",
    "            print_color('Plot will open in Internet browser, please wait...')\n",
    "            tsne_plot2(products, title='Selected `products` between others', selection=out_[2])\n",
    "\n",
    "    if select_continue == 2:\n",
    "        # Multiple entries until the user press `Enter` to finish\n",
    "        # https://www.geeksforgeeks.org/python-get-a-list-as-input-from-user/\n",
    "        try:\n",
    "            select_list = list()\n",
    "            while True:\n",
    "                select_ = read_positive(message_try='Product number [ENTER to finish]: ', allow_enter=True)\n",
    "                select_list.append(select_)\n",
    "        except:\n",
    "            out_ = basket_input_product_list(select_list)\n",
    "            print_color('Selected:')\n",
    "            print(out_[1])\n",
    "            print('\\n')\n",
    "            print_color('Recommendation:')\n",
    "            print(out_[0])\n",
    "            print('\\n')\n",
    "            print_color('Plot will open in Internet browser, please wait...')\n",
    "            tsne_plot2(products, title='Selected `products` between others', selection=out_[2])\n",
    "\n",
    "    elif select_continue == 3:\n",
    "        select_ = read_positive(message_try='Reference user: ')\n",
    "        out_ = basket_input_user(select_)\n",
    "        print_color('Similar to users:')\n",
    "        print(out_[1])\n",
    "        print('\\n')\n",
    "        print_color('Products purchased in previous orders:')\n",
    "        print(out_[3])\n",
    "        print('\\n')\n",
    "        print_color('Recommendation:')\n",
    "        print(out_[0])\n",
    "        print('\\n')\n",
    "        print_color('Plot will open in Internet browser, please wait...')\n",
    "        tsne_plot2(df_user_basket, title='Selected `user` between others', selection=out_[2], hover='user_id')\n",
    "\n",
    "    elif select_continue == 4:\n",
    "        try:\n",
    "            select_list = list()\n",
    "            while True:\n",
    "                select_ = read_positive(message_try='User number [e.g., [23, 27, 66]. ENTER to finish]: ', allow_enter=True)\n",
    "                select_list.append(select_)\n",
    "        except:\n",
    "            out_ = basket_input_user_list(select_list)\n",
    "            print_color('Selected:')\n",
    "            print(out_[1])\n",
    "            print('\\n')\n",
    "            print_color('Products purchased in previous orders:')\n",
    "            print(out_[3])\n",
    "            print('\\n')\n",
    "            print_color('Recommendation:')\n",
    "            print(out_[0])\n",
    "            print('\\n')\n",
    "            print_color('Plot will open in Internet browser, please wait...')\n",
    "            tsne_plot2(df_user_basket, title='Selected `users` between others', selection=out_[2], hover='user_id')\n",
    "\n",
    "    elif select_continue == 5:\n",
    "        select_ = read_positive(message_try='Reference order: ')\n",
    "        out_ = basket_input_order(select_)\n",
    "        print_color('Products purchased in previous orders:')\n",
    "        print(out_[2])\n",
    "        print('\\n')\n",
    "        print_color('Recommendation:')\n",
    "        print(out_[0])\n",
    "        print('\\n')\n",
    "        print_color('Plot will open in Internet browser, please wait...')\n",
    "        tsne_plot2(df_order_baskets, title='Selected `order` between others', selection=out_[1], hover='order_id')\n",
    "\n",
    "    elif select_continue == 6:\n",
    "        print_color('Please wait')\n",
    "        # Create 3 different plots using TSNE algorithm\n",
    "        tsne_plot(products, title='Products', color='department_id', product_flag=True)\n",
    "        tsne_plot(df_user_basket, title='User average', color='user_id')\n",
    "        tsne_plot(df_order_baskets, title='Order average', color='order_id')\n",
    "        print_color('Done. Check your Internet browser.')\n",
    "\n",
    "    elif select_continue == 7:\n",
    "        print_color('Please wait')\n",
    "        ProfileReport(products[['product_id', 'product_name', 'department', 'aisle']], title=\"Exploratory Data Analysis: `Products`\").to_file(\"EDA/eda_products.html\")\n",
    "        ProfileReport(orders, title=\"Exploratory Data Analysis: `Orders and Users`\").to_file(\"EDA/eda_orders_users.html\")\n",
    "        ProfileReport(orders_filter, title=\"Exploratory Data Analysis: `Orders and Products` (filtered)\").to_file(\"EDA/eda_orders_products.html\")\n",
    "        print_color('Done. Check `EDA` folder.')\n",
    "\n",
    "    elif select_continue == 8:\n",
    "        print_color('Check popup window')\n",
    "        eda(order_baskets, orders_filter, products)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
